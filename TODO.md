- [ ] Parallelization
- [ ] Optimizers, gradient boosting, momentum, etc.?
- [ ] Train on MNIST (include in blog post). Maybe the title is gonna be something like "Digit Recognition From Scratch in Haskell"
- [ ] Fully learn all the math and how to derive the backprop formulas
- [ ] Write blog post

- [x] Fix issues, lr must be set to 10 in order for it to predict XOR correctly
- [x] Create a proper trainer framework for the neural net, also do some type foolery probably | type (`Trainer`?) that contains all hyperparameters (lr, epochs, etc.)
- [x] Add better documentation in the form of comments
- [x] Framework for training on MNIST
- [x] Activation function type
- [x] Implement feature to be able to save parameters to disk so there's no need to re-train the network each time
